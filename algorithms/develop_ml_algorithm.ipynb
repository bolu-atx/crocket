{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/bhsu/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from collections import deque\n",
    "from datetime import datetime\n",
    "from decimal import Decimal\n",
    "from enum import Enum\n",
    "from itertools import cycle\n",
    "from math import floor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import randrange, seed\n",
    "from os.path import join\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from keras.models import load_model, Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#path = '/home/b3arjuden/crocket/sql_data/PRODUCTION40'\n",
    "\n",
    "path = '/Users/bhsu/crypto/sql_data/PRODUCTION40'\n",
    "\n",
    "file = 'BTC-ETH.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-8ffdc9ae479b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m data = pd.read_csv(file_path, \n\u001b[1;32m      4\u001b[0m                    \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'buy_order'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sell_order'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                    converters={'price': Decimal,\n",
      "\u001b[0;31mNameError\u001b[0m: name 'path' is not defined"
     ]
    }
   ],
   "source": [
    "file_path = join(path, file)\n",
    "\n",
    "data = pd.read_csv(file_path, \n",
    "                   dtype={'time': str, 'buy_order': int, 'sell_order': int},\n",
    "                   converters={'price': Decimal,\n",
    "                               'wprice': Decimal,\n",
    "                               'base_volume': Decimal,\n",
    "                               'buy_volume': Decimal,\n",
    "                               'sell_volume': Decimal})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def time_transform(df, n):\n",
    "    \n",
    "    df1 = pd.DataFrame()\n",
    "    \n",
    "    nrows = n * floor(df.shape[0] / n)\n",
    "    df = df.iloc[:nrows, :]\n",
    "    \n",
    "    df1['time'] = df.loc[df.index[::n], 'time'].reset_index(drop=True)\n",
    "    df1['open'] = (df.loc[::n, 'wprice'].values)\n",
    "    df1['high'] = (df.loc[:, 'wprice'].groupby(df.index // n).max()) # TODO: estimate using 2 standard deviation from mean\n",
    "    df1['low'] = (df.loc[:, 'wprice'].groupby(df.index // n).min()) # TODO: estimate using 2 standard deciation from mean \n",
    "    df1['close'] = (df.loc[(n-1)::n, 'wprice'].values)\n",
    "    \n",
    "    df1['buy_volume'] = df.loc[:, 'buy_volume'].groupby(df.index // n).sum()\n",
    "    df1['sell_volume'] = df.loc[:, 'sell_volume'].groupby(df.index // n).sum()\n",
    "    df1['buy_order'] = df.loc[:, 'buy_order'].groupby(df.index // n).sum()\n",
    "    df1['sell_order'] = df.loc[:, 'sell_order'].groupby(df.index // n).sum()\n",
    "    \n",
    "    #df1['wprice'] = ((df.loc[:, 'wprice'] * df.loc[:, 'base_volume']).groupby(df.index // n).sum() / \n",
    "    #                 df.loc[:, 'base_volume'].groupby(df.index // n).sum()).apply(lambda x: float(x.quantize(Decimal(10) ** -8)))\n",
    "    \n",
    "    return df1\n",
    "\n",
    "def vectorize(array):\n",
    "    \n",
    "    return np.expand_dims(np.expand_dims(array, axis=0), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    \n",
    "    def __init__(self, \n",
    "                 num_actions,\n",
    "                 checkpoint_path=None):\n",
    "        \n",
    "        self.checkpoint_path = checkpoint_path\n",
    "        \n",
    "        self.count_states = 0\n",
    "        self.count_episodes = 0\n",
    "    \n",
    "    def build(self):\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(LSTM(18, batch_input_shape=(1, 1, 2), activation='tanh', stateful=True))\n",
    "        \n",
    "        model.add(Dense(3, activation='softmax'))\n",
    "        \n",
    "        # Optimizer: adam, RMSProp\n",
    "        model.compile(optimizer='adam', loss='mse')\n",
    "        \n",
    "        self.model = model\n",
    "    \n",
    "    def save(self):\n",
    "        \n",
    "        save_file = 'network_S{}_E{}.h5'.format(self.count_states, self.count_episodes)\n",
    "        model.save(join(self.checkpoint_path, save_file))\n",
    "    \n",
    "    def load(self, model_path):\n",
    "        \n",
    "        self.model = load_model(model_path)\n",
    "        \n",
    "        # TODO: load count_states and count_episodes from file\n",
    "    \n",
    "    def get_weights(self):\n",
    "        \n",
    "        return [layer.get_weights() for layer in self.model.layers]\n",
    "    \n",
    "    def set_weights(self, weights):\n",
    "        \n",
    "        for layer, new_weights in zip(self.model.layers, weights):\n",
    "            layer.set_weights(new_weights)\n",
    "    \n",
    "    def interpolate_weights(self, weights, interpolation_factor=0.001):\n",
    "        \n",
    "        for layer, new_weights in zip(self.model.layers, weights):\n",
    "            layer.set_weights([w1 * interpolation_factor + (1 - interpolation_factor) * w0 for w0, w1 in zip(layer.get_weights(), new_weights)])\n",
    "    \n",
    "    # TODO: add initialization function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    \"\"\"\n",
    "    Rules:\n",
    "    - Position = 0 -> HOLD, BUY\n",
    "    - Position => 1 -> HOLD, SELL\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, parameters):\n",
    "        \n",
    "        self.num_actions = parameters.num_actions\n",
    "        self.discount_factor = parameters.discount_factor\n",
    "        self.epsilon = parameters.epsilon\n",
    "        self.epsilon_min = parameters.epsilon_min\n",
    "        self.epsilon_decay = parameters.epsilon_decay\n",
    "        self.priority_alpha = parameters.priority_alpha\n",
    "        self.batch_size = parameters.batch_size\n",
    "        \n",
    "        self.prioritized_memory = parameters.prioritized_memory\n",
    "        self.replay_capacity = parameters.replay_capacity\n",
    "        self.state_length = parameters.state_length\n",
    "        self.priority_epsilon = parameters.priority_epsilon\n",
    "        \n",
    "        self._initialize()\n",
    "        \n",
    "    def _initialize(self, model_path=None):\n",
    "        \n",
    "        self.train_network = NeuralNetwork(num_actions=self.num_actions)\n",
    "        self.target_network = NeuralNetwork(num_actions=self.num_actions)\n",
    "        \n",
    "        if model_path:\n",
    "            pass\n",
    "            # TODO: implement load model from folder (network_weights, replay_memory, additional_params)\n",
    "        else:\n",
    "            \n",
    "            if self.prioritized_memory:\n",
    "                self.replay_memory = PrioritizedReplayMemory(capacity=self.replay_capacity)\n",
    "            else:\n",
    "                self.replay_memory = ReplayMemory(capacity=self.replay_capacity,\n",
    "                                                  state_shape=self.state_length,\n",
    "                                                  num_actions=self.num_actions)\n",
    "\n",
    "            self.train_network.build()\n",
    "            self.target_network.build()\n",
    "            \n",
    "            self.target_network.set_weights(self.train_network.get_weights())\n",
    "        \n",
    "    def act(self, state):\n",
    "        \n",
    "        # no position -> actions allowed: HOLD, BUY\n",
    "        # active position -> HOLD, BUY, SELL\n",
    "        \n",
    "        buy_price = state[-1]\n",
    "        \n",
    "        if buy_price == 0:\n",
    "            actions = [0, 1]\n",
    "        else:\n",
    "            actions = [0, 2]\n",
    "            \n",
    "        if np.random.rand() < self.epsilon:\n",
    "            return actions[np.random.randint(2)]\n",
    "        \n",
    "        values = self.train_network.model.predict(vectorize(state))\n",
    "        \n",
    "        return actions[np.argmax(values[0][actions])]\n",
    "    \n",
    "    def replay(self):\n",
    "        \"\"\"\n",
    "        Replay options: 1) replay memory, 2) prioritized replay memory\n",
    "        \"\"\"\n",
    "        if self.prioritized_memory:\n",
    "            idx, priorities, experience = self.replay_memory.sample(self.batch_size)\n",
    "            \n",
    "            # Update transition priorities\n",
    "        else:\n",
    "            episodes = self.replay_memory.random_batch(self.batch_size)\n",
    "            \n",
    "            for e in episodes:\n",
    "                \n",
    "                states_batch = np.array(e.states)\n",
    "                action_batch = np.array(e.actions)\n",
    "                rewards_batch = np.array(e.rewards)\n",
    "                next_states_batch = np.array(e.next_states)\n",
    "                \n",
    "                for state, action, reward, next_state in (states_batch, action_batch, rewards_batch, next_states_batch):\n",
    "                    \n",
    "                    q_values_next = self.train_network.model.predict(next_states_batch)\n",
    "                    best_actions = np.argmax(q_values_next, axis=1)\n",
    "                    q_values_next_target = self.target_network.model.predict(next_states_batch)\n",
    "\n",
    "                    # SELL equivalent to end of episode\n",
    "                    targets_batch = reward_batch + \\\n",
    "                        (action_batch != 2).astype(int) * (self.discount_factor * np.repeat(q_values_next_target[np.arange(self.batch_size), best_actions].reshape(self.batch_size, 1), self.num_actions, axis=1))\n",
    "\n",
    "                    targets_batch = targets_batch * np.stack([[1, 1, 0] if x[-1, -1] == 0 else [1, 0, 1] for x in states_batch])\n",
    "\n",
    "                    # TODO: consider clip reward\n",
    "                    # Update train model\n",
    "                    self.train_network.model.fit(states_batch, targets_batch)\n",
    "                \n",
    "                self.train_network.reset_states()\n",
    "\n",
    "            if self.epsilon > self.epsilon_min:\n",
    "                self.epsilon *= self.epsilon_decay\n",
    "    \n",
    "    def initialize_replay_memory(self, env, parameters, price_index):\n",
    "        \n",
    "        print('Initializing replay memory...')\n",
    "        \n",
    "        for e in range(parameters.replay_capacity):\n",
    "            \n",
    "            episode = Episode()\n",
    "            state = env.reset()\n",
    "            \n",
    "            for idx in range(env.steps):\n",
    "                \n",
    "                action = self.act(state)\n",
    "                next_state, reward, _ = env.step(action, price_index)\n",
    "\n",
    "                if self.prioritized_memory:\n",
    "                    # TODO: refactor\n",
    "                    self.replay_memory.add((state, action, reward, next_state), max(self.priority_max, self.priority_epsilon))\n",
    "                else:\n",
    "                    episode.add(state, action, reward, next_state)\n",
    "\n",
    "                state = next_state\n",
    "\n",
    "            state = env.reset()\n",
    "            self.replay_memory.add(episode)\n",
    "            \n",
    "        print('Replay memory initialized.')\n",
    "        \n",
    "    def update_transition_priorities(self, states_batch, actions_batch, rewards_batch, targets_batch, indexes):\n",
    "        \n",
    "        for s0, a, r, t, i in zip(states_batch, actions_batch, rewards_batch, targets_batch, indexes):\n",
    "            \n",
    "            priority = (abs(self.train_network.model.predict(s0)[a] - t[a]) + self.priority_epsilon) ** self.priority_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Episode:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        # TODO: improve performance\n",
    "        self.states = []\n",
    "        self.actions = []\n",
    "        self.rewards = []\n",
    "        self.states_next = []\n",
    "        \n",
    "    def add(self, state, action, reward, next_state):\n",
    "        \n",
    "        self.states.append(state)\n",
    "        self.actions.append(action)\n",
    "        self.rewards.append(reward)\n",
    "        self.states_next.append(next_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ReplayMemory:\n",
    "    \n",
    "    # TODO: use collections.deque\n",
    "    # Store list of episodes\n",
    "        \n",
    "    def __init__(self, capacity, state_shape, num_actions):\n",
    "        \n",
    "        self.capacity = capacity\n",
    "        self.episodes = []\n",
    "        \n",
    "        self.indexes = cycle(range(capacity))\n",
    "        self.pointer = next(self.indexes)\n",
    "        \n",
    "    def add(self, episode):\n",
    "        \n",
    "        k = self.pointer\n",
    "\n",
    "        self.episodes[k] = episode\n",
    "        \n",
    "        self.pointer = next(self.indexes)\n",
    "        \n",
    "    def random_batch(self, batch_size):\n",
    "        \n",
    "        idx = np.random.randint(self.capacity, size=batch_size)\n",
    "        \n",
    "        return self.episodes[idx]\n",
    "    \n",
    "    def random_batch_priority(self, batch_size, non_hold_ratio):\n",
    "        \"\"\"\n",
    "        Sample from hold entries and buy/sell entires separately\n",
    "        \"\"\"\n",
    "        \n",
    "        num_non_hold = int(batch_size * non_hold_ratio)\n",
    "        num_hold = batch_size - num_non_hold\n",
    "        \n",
    "        non_hold_idx = set(i for i, x in enumerate(self.actions) if x[0] != 0)\n",
    "        hold_idx = set(range(self.capacity)) - non_hold_idx\n",
    "        \n",
    "        idx = np.concatenate((np.random.choice(list(hold_idx), size=num_hold), np.random.choice(list(non_hold_idx), size=num_non_hold)))\n",
    "        \n",
    "        return self.states[idx], self.actions[idx], self.rewards[idx], self.states_next[idx], idx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PrioritizedReplayMemory:\n",
    "    \"\"\"\n",
    "    SumTree.\n",
    "    Data: (state, action, reward, next_state)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, capacity):\n",
    "        \n",
    "        self.capacity = capacity\n",
    "        self.tree = np.zeros(2*capacity - 1)\n",
    "        self.data = np.zeros(capacity, dtype=object)\n",
    "        \n",
    "        self.pointer = 0\n",
    "    \n",
    "    def _propagate(self, idx, change):\n",
    "        parent = (idx - 1) // 2\n",
    "\n",
    "        self.tree[parent] += change\n",
    "\n",
    "        if parent != 0:\n",
    "            self._propagate(parent, change)\n",
    "\n",
    "    def _retrieve(self, idx, s):\n",
    "        left = 2 * idx + 1\n",
    "\n",
    "        if left >= self.tree_len:\n",
    "            return idx\n",
    "\n",
    "        if s <= self.tree[left]:\n",
    "            return self._retrieve(left, s)\n",
    "        else:\n",
    "            right = left + 1\n",
    "            return self._retrieve(right, s-self.tree[left])\n",
    "\n",
    "    def total(self):\n",
    "        return self.tree[0]\n",
    "\n",
    "    def add(self, data, p):\n",
    "        idx = self.pointer + self.capacity - 1\n",
    "\n",
    "        self.data[self.pointer] = data\n",
    "        self.update(idx, p)\n",
    "\n",
    "        self.pointer += 1\n",
    "        \n",
    "        if self.pointer >= self.capacity:\n",
    "            self.pointer = 0\n",
    "\n",
    "    def update(self, idx, p):\n",
    "        change = p - self.tree[idx]\n",
    "\n",
    "        self.tree[idx] = p\n",
    "        self._propagate(idx, change)\n",
    "\n",
    "    def get(self, s):\n",
    "        idx = self._retrieve(0, s)\n",
    "        data_idx = idx - self.capacity + 1\n",
    "\n",
    "        return idx, self.tree[idx], self.data[data_idx]\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        batch_idx = [None] * batch_size\n",
    "        batch_priorities = [None] * batch_size\n",
    "        batch = [None] * batch_size\n",
    "        segment = self.total() / batch_size\n",
    "\n",
    "        a = [segment*i for i in range(batch_size)]\n",
    "        b = [segment * (i+1) for i in range(batch_size)]\n",
    "        s = np.random.uniform(a, b)\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            (batch_idx[i], batch_priorities[i], batch[i]) = self.get(s[i])\n",
    "\n",
    "        return batch_idx, batch_priorities, batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    \n",
    "    def __init__(self,\n",
    "                 input_data,\n",
    "                 steps=None):\n",
    "        \n",
    "        self.steps = steps\n",
    "        self._load(input_data)\n",
    "        \n",
    "        self.episode = {}\n",
    "        \n",
    "    def _load(self, input_data):\n",
    "        \n",
    "        self.data = input_data\n",
    "        \n",
    "        self.shape = input_data.shape\n",
    "        \n",
    "        if self.steps is None or self.steps > self.shape[0]:\n",
    "            self.steps = self.shape[0] - 1\n",
    "    \n",
    "    def _seed(self):\n",
    "        \n",
    "        seed()\n",
    "        \n",
    "    def reset(self):\n",
    "        \n",
    "        self._seed()\n",
    "        self.episode['start'] = np.random.randint(0, self.shape[0] - self.steps)\n",
    "        self.episode['current_index'] = self.episode.get('start')\n",
    "        self.data[:, -1] = 0  # Reset buy state\n",
    "        \n",
    "        return self.data[self.episode.get('current_index')]\n",
    "        \n",
    "    def step(self, action, price_index):\n",
    "        \n",
    "        current_index = self.episode.get('current_index')\n",
    "        state = self.data[current_index]\n",
    "        next_state = self.data[current_index + 1]\n",
    "\n",
    "        price = state[0]\n",
    "        buy_price = state[-1]\n",
    "        \n",
    "        if action == 1:\n",
    "            next_state[-1] = price\n",
    "            reward = [0, price * -1, 0]\n",
    "        elif action == 2:\n",
    "            next_state[-1] = 0\n",
    "            reward = [0, 0, price - buy_price]\n",
    "        else:\n",
    "            # TODO: set reward to difference between buy_price and current_price if position held, but smaller magnitude than buying or selling\n",
    "            next_state[-1] = buy_price\n",
    "            reward = [0, 0, 0]\n",
    "        \n",
    "        self.episode['current_index'] += 1\n",
    "        \n",
    "        return next_state, reward, current_index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Action(Enum):\n",
    "\n",
    "    HOLD = 0\n",
    "    BUY = 1\n",
    "    SELL = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Summary:\n",
    "    \n",
    "    def __init__(self, parameters=None):\n",
    "        \n",
    "        self.episodes = []\n",
    "        self.params = parameters\n",
    "        \n",
    "    def create(self, actions, train_reward, actual_reward, start, end, epsilon_end):\n",
    "        \n",
    "        # TODO: add epsilon values\n",
    "        \n",
    "        self.episodes.append({\n",
    "            'actions': actions,\n",
    "            'train_reward': train_reward,\n",
    "            'actual_reward': actual_reward,\n",
    "            'start': start,\n",
    "            'end': end,\n",
    "            'epsilon_end': epsilon_end\n",
    "        })\n",
    "        \n",
    "    def summarize_all(self):\n",
    "        \n",
    "        num_episodes = len(self.episodes)\n",
    "        train_reward = np.zeros(num_episodes)\n",
    "        actual_reward = np.zeros(num_episodes)\n",
    "        epsilon_end = np.zeros(num_episodes)\n",
    "        \n",
    "        for ii in range(num_episodes):\n",
    "            train_reward[ii], actual_reward[ii], epsilon_end[ii] = (self.episodes[ii][x] for x in ['train_reward', 'actual_reward', 'epsilon_end'])\n",
    "        \n",
    "        # TODO: add plot here\n",
    "        \n",
    "        return train_reward, actual_reward, epsilon_end\n",
    "    \n",
    "    def summarize_episode(self, episode_num):\n",
    "        \n",
    "        episode_summary = self.episodes[episode_num]\n",
    "        \n",
    "        return episode_summary\n",
    "    \n",
    "    def get_price(self, price, episode_num):\n",
    "        \n",
    "        start = self.episodes[episode_num].get('start')\n",
    "        end = self.episodes[episode_num].get('end')\n",
    "        \n",
    "        return price[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data processing parameters\n",
    "n = 15\n",
    "m = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test data\n",
    "x = np.linspace(-np.pi, np.pi, 100)\n",
    "array = np.sin(x)\n",
    "\n",
    "price_state_index = -1\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "normalized_array = min_max_scaler.fit_transform(array.reshape(-1, 1))\n",
    "\n",
    "# Build states\n",
    "#states = np.array([normalized_array[x:x+m, :] for x in range(normalized_array.shape[0] - m + 1)])\n",
    "states = normalized_array\n",
    "\n",
    "# Add state for position held\n",
    "states = np.insert(states, states.shape[1], 0, axis=1)\n",
    "\n",
    "# Build prices\n",
    "prices = list(map(float, array[(m-1):]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Combine data\n",
    "df = time_transform(data.iloc[:200*15,:], n)\n",
    "array = df.iloc[:,1:].as_matrix()\n",
    "\n",
    "# Get close price column index\n",
    "price_df_index = df.columns.get_loc('close')\n",
    "price_array_index = price_df_index-1\n",
    "price_state_index = m*(price_array_index+1)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Normalize data \n",
    "# TODO: change normalization if necessary\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "normalized_array = min_max_scaler.fit_transform(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Build states\n",
    "states = np.array([normalized_array[x:x+m, :] for x in range(normalized_array.shape[0] - m + 1)])\n",
    "\n",
    "# Add state for position\n",
    "states = np.insert(states, states.shape[2], 0, axis=2)\n",
    "\n",
    "# Build prices\n",
    "prices = list(map(float, array[(m-1):, price_array_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Parameters:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        # Time series parameters\n",
    "        self.num_actions = 3\n",
    "        \n",
    "        # Neural network parameters\n",
    "        self.discount_factor = 0.97\n",
    "        self.epsilon = 0.99\n",
    "        self.epsilon_min = 0.1\n",
    "        self.epsilon_decay = 0.98\n",
    "        \n",
    "        # Replay memory parameters\n",
    "        self.replay_capacity = 10000\n",
    "        self.batch_size = 100\n",
    "        self.priority_epsilon = 1e-6\n",
    "        self.priority_alpha = 2\n",
    "        self.prioritized_memory = False\n",
    "        \n",
    "        # Training parameters\n",
    "        self.episodes = 1\n",
    "        self.episode_length = 92\n",
    "        self.update_target_weights_step_size = 200\n",
    "        self.train_network_step_size = 100\n",
    "        self.interpolation_factor = 0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing replay memory...\n",
      "Replay memory initialized.\n",
      "Step 0: Updating target Q network weights with latest Q network weights.\n",
      "Step 0: Sampling replay memory and training Q network.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking : expected lstm_22_input to have 3 dimensions, but got array with shape (100, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-463f0cf5632e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Step {}: Sampling replay memory and training Q network.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-89-cdd290f21778>\u001b[0m in \u001b[0;36mreplay\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mstates_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_states_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mq_values_next\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_states_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m             \u001b[0mbest_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_values_next\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mq_values_next_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_states_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1004\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1770\u001b[0m         x = _standardize_input_data(x, self._feed_input_names,\n\u001b[1;32m   1771\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1772\u001b[0;31m                                     check_batch_axis=False)\n\u001b[0m\u001b[1;32m   1773\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    139\u001b[0m                                  \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                                  \u001b[0;34m' dimensions, but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                                  str(array.shape))\n\u001b[0m\u001b[1;32m    142\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_dim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking : expected lstm_22_input to have 3 dimensions, but got array with shape (100, 2)"
     ]
    }
   ],
   "source": [
    "## Model training\n",
    "\n",
    "parameters = Parameters()\n",
    "parameters.state_length = list(states[0].shape)\n",
    "agent = Agent(parameters)\n",
    "env = Environment(states, steps=parameters.episode_length)\n",
    "summary = Summary()\n",
    "step = 0\n",
    "\n",
    "# Populate the replay memory with initial experiences\n",
    "agent.initialize_replay_memory(env, parameters, price_index=price_state_index)\n",
    "\n",
    "for e in range(parameters.episodes):\n",
    "    \n",
    "    state = env.reset()\n",
    "    \n",
    "    episode_learn_reward = 0\n",
    "    episode_actions = np.zeros(parameters.episode_length)\n",
    "    episode_actual_reward = 0\n",
    "    \n",
    "    for ii in range(parameters.episode_length):\n",
    "        \n",
    "        # Update the target network weights every X iterations\n",
    "        if step % parameters.update_target_weights_step_size == 0:\n",
    "            print('Step {}: Updating target Q network weights with latest Q network weights.'.format(step))\n",
    "            agent.target_network.interpolate_weights(agent.train_network.get_weights(), parameters.interpolation_factor)\n",
    "                \n",
    "        action = agent.act(state)\n",
    "        next_state, reward, index = env.step(action, price_index=price_state_index)\n",
    "        agent.replay_memory.add(state, action, reward, next_state)\n",
    "        state = next_state\n",
    "        \n",
    "        episode_actions[ii] = action\n",
    "        episode_learn_reward += reward[action]\n",
    "        \n",
    "        if action > 0:\n",
    "            price = prices[index]\n",
    "            episode_actual_reward += price * -1.0025 if action == 1 else price * 0.9975\n",
    "        \n",
    "        if step % parameters.train_network_step_size == 0:\n",
    "            print('Step {}: Sampling replay memory and training Q network.'.format(step))\n",
    "            \n",
    "            agent.replay()\n",
    "            \n",
    "        step += 1\n",
    "\n",
    "    agent\n",
    "    \n",
    "    summary.create(episode_actions, episode_learn_reward, episode_actual_reward, env.episode.get('start'), env.episode.get('current_index')+1, agent.epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.models.Sequential at 0x1a25d86f98>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.train_network.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.5,  0. ]]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expand_dims(np.expand_dims(states[0, :], axis=0), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training reward: -2.9763699772305374\n",
      "Actual reward: -0.6417023712198706\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1a2a5143c8>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKaUq0MKglFKqAi0MSimlKvh/IIZLHdSoIXQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a2a882ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Examine episode\n",
    "\n",
    "episode_num = 997\n",
    "\n",
    "episode_summary = summary.summarize_episode(episode_num)\n",
    "episode_price = summary.get_price(prices, episode_num)\n",
    "actions = episode_summary.get('actions')\n",
    "\n",
    "print('Training reward: {}'.format(episode_summary.get('train_reward')))\n",
    "print('Actual reward: {}'.format(episode_summary.get('actual_reward')))\n",
    "\n",
    "# Plot graph of buy/sell actions\n",
    "buy_indices = [x for x in range(len(actions)) if actions[x] == 1]\n",
    "buy_prices = [episode_price[x] for x in buy_indices]\n",
    "\n",
    "sell_indices = [x for x in range(len(actions)) if actions[x] == 2]\n",
    "sell_prices = [episode_price[x] for x in sell_indices]\n",
    "\n",
    "plt.plot(episode_price)\n",
    "plt.scatter(buy_indices, buy_prices, color='r')\n",
    "plt.scatter(sell_indices, sell_prices, color='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.replay_memory.rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, actual, epsilon = summary.summarize_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a27458e48>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a2592eb38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-62c28af66297>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mchoice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mone_indexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_train\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mone_indexes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m  \u001b[0;31m# very long term memory.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "N_train = 1000\n",
    "from numpy.random import choice\n",
    "one_indexes = choice(a=N_train, size=int(N_train / 2), replace=False)\n",
    "X_train[one_indexes, 0] = 1  # very long term memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Neural network playground\n",
    "\n",
    "# RNN - calls to predict store state history\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(2, batch_input_shape=(1, 1, 2), activation='tanh', stateful=True))\n",
    "\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# Optimizer: adam, RMSProp\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('test_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_model = load_model('test_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.73093283, -0.3637661 , -0.50931585,  0.47428238,  0.46101344,\n",
       "         -0.53180337,  0.64970565, -0.63791853],\n",
       "        [ 0.01188666, -0.04821819, -0.1984486 , -0.55533558, -0.45577481,\n",
       "         -0.30892774, -0.40100241, -0.5112372 ]], dtype=float32),\n",
       " array([[ 0.31900868,  0.09988321,  0.13011806, -0.00228098,  0.76533043,\n",
       "          0.00229885, -0.16670036, -0.50773609],\n",
       "        [-0.14532249,  0.53168344,  0.13678308,  0.27481109, -0.29851779,\n",
       "         -0.3401365 , -0.59445935, -0.20922652]], dtype=float32),\n",
       " array([ 0.,  0.,  1.,  1.,  0.,  0.,  0.,  0.], dtype=float32),\n",
       " array([[ 0.55039096, -0.9745031 , -0.80169487],\n",
       "        [ 0.36104786, -0.00757515,  0.5540576 ]], dtype=float32),\n",
       " array([ 0.,  0.,  0.], dtype=float32)]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.73093283, -0.3637661 , -0.50931585,  0.47428238,  0.46101344,\n",
       "         -0.53180337,  0.64970565, -0.63791853],\n",
       "        [ 0.01188666, -0.04821819, -0.1984486 , -0.55533558, -0.45577481,\n",
       "         -0.30892774, -0.40100241, -0.5112372 ]], dtype=float32),\n",
       " array([[ 0.31900868,  0.09988321,  0.13011806, -0.00228098,  0.76533043,\n",
       "          0.00229885, -0.16670036, -0.50773609],\n",
       "        [-0.14532249,  0.53168344,  0.13678308,  0.27481109, -0.29851779,\n",
       "         -0.3401365 , -0.59445935, -0.20922652]], dtype=float32),\n",
       " array([ 0.,  0.,  1.,  1.,  0.,  0.,  0.,  0.], dtype=float32),\n",
       " array([[ 0.55039096, -0.9745031 , -0.80169487],\n",
       "        [ 0.36104786, -0.00757515,  0.5540576 ]], dtype=float32),\n",
       " array([ 0.,  0.,  0.], dtype=float32)]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.33997616,  0.33627522,  0.32374865]], dtype=float32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(vectorize(states[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4446\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a234a3940>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(vectorize(states[0]), np.expand_dims(np.array([1, 1, 1]), axis=0), batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 896ms/step - loss: 0.4446\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a241c5eb8>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model.fit(vectorize(states[0]), np.expand_dims(np.array([1, 1, 1]), axis=0), batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.73192817, -0.36442012, -0.51030493,  0.47381532,  0.46001396,\n",
       "         -0.53086317,  0.6487118 , -0.63858837],\n",
       "        [ 0.01188666, -0.04821819, -0.1984486 , -0.55533558, -0.45577481,\n",
       "         -0.30892774, -0.40100241, -0.5112372 ]], dtype=float32),\n",
       " array([[ 0.31805012,  0.09971247,  0.12921   , -0.00236812,  0.76433527,\n",
       "          0.00293026, -0.16764657, -0.50791705],\n",
       "        [-0.14436556,  0.53184849,  0.13768768,  0.27489504, -0.29752281,\n",
       "         -0.34075838, -0.59351528, -0.2090515 ]], dtype=float32),\n",
       " array([ -9.97651601e-04,  -7.90818245e-04,   9.99005497e-01,\n",
       "          9.99363303e-01,  -9.99736832e-04,   9.69187764e-04,\n",
       "         -9.96913644e-04,  -8.02258786e-04], dtype=float32),\n",
       " array([[ 0.54939252, -0.97350794, -0.80069715],\n",
       "        [ 0.36204627, -0.00857013,  0.55305994]], dtype=float32),\n",
       " array([-0.00099992,  0.00099974,  0.00099988], dtype=float32)]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.73192817, -0.36442012, -0.51030493,  0.47381532,  0.46001396,\n",
       "         -0.53086317,  0.6487118 , -0.63858837],\n",
       "        [ 0.01188666, -0.04821819, -0.1984486 , -0.55533558, -0.45577481,\n",
       "         -0.30892774, -0.40100241, -0.5112372 ]], dtype=float32),\n",
       " array([[ 0.31805012,  0.09971247,  0.12921   , -0.00236812,  0.76433527,\n",
       "          0.00293026, -0.16764657, -0.50791705],\n",
       "        [-0.14436556,  0.53184849,  0.13768768,  0.27489504, -0.29752281,\n",
       "         -0.34075838, -0.59351528, -0.2090515 ]], dtype=float32),\n",
       " array([ -9.97651601e-04,  -7.90818245e-04,   9.99005497e-01,\n",
       "          9.99363303e-01,  -9.99736832e-04,   9.69187764e-04,\n",
       "         -9.96913644e-04,  -8.02258786e-04], dtype=float32),\n",
       " array([[ 0.54939252, -0.97350794, -0.80069715],\n",
       "        [ 0.36204627, -0.00857013,  0.55305994]], dtype=float32),\n",
       " array([-0.00099992,  0.00099974,  0.00099988], dtype=float32)]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.13670987, -0.25626671,  0.35413641,  0.05407447, -0.23540521,\n",
       "         -0.00872707, -0.23882103, -0.21924084],\n",
       "        [ 0.14995754, -0.37987173,  0.73043746,  0.51833218, -0.41518304,\n",
       "         -0.30856588,  0.32293063,  0.43715757],\n",
       "        [-0.14346653, -0.58722466,  0.09635061, -0.42959249, -0.12475342,\n",
       "          0.48008007,  0.20320719,  0.52007014]], dtype=float32),\n",
       " array([[ -1.19848497e-01,  -1.05012525e-02,  -2.84707963e-01,\n",
       "           4.05847937e-01,  -5.25312759e-02,   3.98373187e-01,\n",
       "          -4.87123698e-01,  -5.83956063e-01],\n",
       "        [  3.55554948e-04,   6.20316327e-01,  -3.83881956e-01,\n",
       "          -1.94700994e-02,  -1.86089277e-01,   1.41730011e-01,\n",
       "          -3.30079406e-01,   5.51175177e-01]], dtype=float32),\n",
       " array([ 0.,  0.,  1.,  1.,  0.,  0.,  0.,  0.], dtype=float32),\n",
       " array([[ 0.35717392],\n",
       "        [-1.1435802 ]], dtype=float32),\n",
       " array([ 0.], dtype=float32)]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.14307576,  0.53988099, -0.08345276,  0.15672588,  0.24964613,\n",
       "          0.12790012, -0.07451165, -0.20258969, -0.34309155,  0.31779039,\n",
       "          0.60426831, -0.50093889],\n",
       "        [ 0.5596348 ,  0.26232028,  0.15591896,  0.11767244, -0.25093207,\n",
       "         -0.03600758, -0.03117216,  0.58335876,  0.25778687,  0.56229258,\n",
       "          0.3730216 , -0.4971121 ]], dtype=float32),\n",
       " array([[ 0.17935   ,  0.10540307,  0.39597896,  0.24963087, -0.27444357,\n",
       "         -0.5804953 , -0.36762106,  0.07931638, -0.12631567, -0.3159796 ,\n",
       "          0.26089209, -0.00387509],\n",
       "        [ 0.19038658, -0.21856263,  0.11403145,  0.13949299,  0.04758941,\n",
       "         -0.23152837,  0.49736854, -0.26391017, -0.24368083, -0.2290431 ,\n",
       "         -0.42155778,  0.4701868 ],\n",
       "        [ 0.18658625,  0.34733692, -0.11857619,  0.00143213, -0.5228526 ,\n",
       "         -0.09826455,  0.40348285,  0.39495933,  0.40627801, -0.01568197,\n",
       "         -0.23384646, -0.09309311]], dtype=float32),\n",
       " array([ 0.,  0.,  0.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.], dtype=float32),\n",
       " array([[-0.40650415, -0.94694066, -0.32358479],\n",
       "        [ 0.66262436,  0.75632429,  0.57618499],\n",
       "        [ 0.32545233,  0.23536563, -0.09811139]], dtype=float32),\n",
       " array([ 0.,  0.,  0.], dtype=float32)]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.33073106,  0.33260202,  0.33666694]], dtype=float32)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model.predict(vectorize(states[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_model.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.33073106,  0.33260202,  0.33666694]], dtype=float32)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model.predict(vectorize(states[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.14307576,  0.53988099, -0.08345276,  0.15672588,  0.24964613,\n",
       "          0.12790012, -0.07451165, -0.20258969, -0.34309155,  0.31779039,\n",
       "          0.60426831, -0.50093889],\n",
       "        [ 0.5596348 ,  0.26232028,  0.15591896,  0.11767244, -0.25093207,\n",
       "         -0.03600758, -0.03117216,  0.58335876,  0.25778687,  0.56229258,\n",
       "          0.3730216 , -0.4971121 ]], dtype=float32),\n",
       " array([[ 0.17935   ,  0.10540307,  0.39597896,  0.24963087, -0.27444357,\n",
       "         -0.5804953 , -0.36762106,  0.07931638, -0.12631567, -0.3159796 ,\n",
       "          0.26089209, -0.00387509],\n",
       "        [ 0.19038658, -0.21856263,  0.11403145,  0.13949299,  0.04758941,\n",
       "         -0.23152837,  0.49736854, -0.26391017, -0.24368083, -0.2290431 ,\n",
       "         -0.42155778,  0.4701868 ],\n",
       "        [ 0.18658625,  0.34733692, -0.11857619,  0.00143213, -0.5228526 ,\n",
       "         -0.09826455,  0.40348285,  0.39495933,  0.40627801, -0.01568197,\n",
       "         -0.23384646, -0.09309311]], dtype=float32),\n",
       " array([ 0.,  0.,  0.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.], dtype=float32),\n",
       " array([[-0.40650415, -0.94694066, -0.32358479],\n",
       "        [ 0.66262436,  0.75632429,  0.57618499],\n",
       "        [ 0.32545233,  0.23536563, -0.09811139]], dtype=float32),\n",
       " array([ 0.,  0.,  0.], dtype=float32)]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
