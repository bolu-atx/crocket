{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/bhsu/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from collections import deque\n",
    "from datetime import datetime\n",
    "from decimal import Decimal\n",
    "from enum import Enum\n",
    "from itertools import cycle\n",
    "from math import floor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import randrange, seed\n",
    "from os.path import join\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#path = '/home/b3arjuden/crocket/sql_data/PRODUCTION40'\n",
    "\n",
    "path = '/Users/bhsu/crypto/sql_data/PRODUCTION40'\n",
    "\n",
    "file = 'BTC-ETH.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_path = join(path, file)\n",
    "\n",
    "data = pd.read_csv(file_path, \n",
    "                   dtype={'time': str, 'buy_order': int, 'sell_order': int},\n",
    "                   converters={'price': Decimal,\n",
    "                               'wprice': Decimal,\n",
    "                               'base_volume': Decimal,\n",
    "                               'buy_volume': Decimal,\n",
    "                               'sell_volume': Decimal})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def time_transform(df, n):\n",
    "    \n",
    "    df1 = pd.DataFrame()\n",
    "    \n",
    "    nrows = n * floor(df.shape[0] / n)\n",
    "    df = df.iloc[:nrows, :]\n",
    "    \n",
    "    df1['time'] = df.loc[df.index[::n], 'time'].reset_index(drop=True)\n",
    "    df1['wprice'] = ((df.loc[:, 'wprice'] * df.loc[:, 'base_volume']).groupby(df.index // n).sum() / \n",
    "                     df.loc[:, 'base_volume'].groupby(df.index // n).sum()).apply(lambda x: float(x.quantize(Decimal(10) ** -8)))\n",
    "    df1['buy_volume'] = df.loc[:, 'buy_volume'].groupby(df.index // n).sum().apply(float)\n",
    "    df1['sell_volume'] = df.loc[:, 'sell_volume'].groupby(df.index // n).sum().apply(float)\n",
    "    df1['buy_order'] = df.loc[:, 'buy_order'].groupby(df.index // n).sum()\n",
    "    df1['sell_order'] = df.loc[:, 'sell_order'].groupby(df.index // n).sum()\n",
    "    \n",
    "    return df1\n",
    "\n",
    "def vectorize(array):\n",
    "    \n",
    "    return np.transpose(array).reshape(1, array.size)\n",
    "\n",
    "def unvectorize(vector, x, y):\n",
    "    \n",
    "    return vector.reshape(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Parameters:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        # Time series parameters\n",
    "        self.num_actions = 3\n",
    "        \n",
    "        # Neural network parameters\n",
    "        self.discount_factor = 0.97\n",
    "        self.epsilon = 0.99\n",
    "        self.epsilon_min = 0.1\n",
    "        self.epsilon_decay = 0.95\n",
    "        \n",
    "        # Replay memory parameters\n",
    "        self.replay_memory_size = 10000\n",
    "        self.batch_size = 128\n",
    "        \n",
    "        # Update parameters\n",
    "        self.update_target_weights_step_size = 100\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    \n",
    "    def __init__(self, \n",
    "                 num_actions, \n",
    "                 checkpoint_path=None):\n",
    "        \n",
    "        self.checkpoint_path = checkpoint_path\n",
    "        \n",
    "        self.count_states = 0\n",
    "        self.count_episodes = 0\n",
    "    \n",
    "    def build(self):\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(Dense(units=30, input_dim=20, activation='relu'))\n",
    "        model.add(Dense(units=3, activation='softmax'))\n",
    "        \n",
    "        # Optimizer: adam, RMSProp\n",
    "        model.compile(optimizer='adam', loss='mse')\n",
    "        \n",
    "        self.model = model\n",
    "    \n",
    "    def save(self):\n",
    "        \n",
    "        save_file = 'network_S{}_E{}.h5'.format(self.count_states, self.count_episodes)\n",
    "        model.save(join(self.checkpoint_path, save_file))\n",
    "    \n",
    "    def load(self, model_path):\n",
    "        \n",
    "        self.model = load_model(model_path)\n",
    "        \n",
    "        # TODO: load count_states and count_episodes from file\n",
    "    \n",
    "    def get_weights(self):\n",
    "        \n",
    "        return [layer.get_weights() for layer in self.model.layers]\n",
    "    \n",
    "    def set_weights(self, weights):\n",
    "        \n",
    "        for layer, new_weights in zip(self.model.layers, weights):\n",
    "            layer.set_weights(new_weights)\n",
    "    \n",
    "    def interpolate_weights(self, weights, interpolation_factor=0.001):\n",
    "        \n",
    "        for layer, new_weights in zip(self.model.layers, weights):\n",
    "            layer.set_weights([w1 * interpolation_factor + (1 - interpolation_factor) * w0 for w0, w1 in zip(layer.get_weights(), new_weights)])\n",
    "    \n",
    "    # TODO: add initialization function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    \n",
    "    def __init__(self, parameters):\n",
    "        \n",
    "        self.num_actions = parameters.num_actions\n",
    "        self.discount_factor = parameters.discount_factor\n",
    "        self.epsilon = parameters.epsilon\n",
    "        self.epsilon_min = parameters.epsilon_min\n",
    "        self.epsilon_decay = parameters.epsilon_decay\n",
    "        \n",
    "        self._initialize()\n",
    "        \n",
    "    def _initialize(self, model_path=None):\n",
    "        \n",
    "        self.train_model = NeuralNetwork(num_actions=self.num_actions)\n",
    "        self.target_model = NeuralNetwork(num_actions=self.num_actions)\n",
    "        \n",
    "        if model_path:\n",
    "            pass\n",
    "            # TODO: implement load model from folder (network_weights, replay_memory, additional_params)\n",
    "        else:\n",
    "            self.replay_memory = ReplayMemory(memory_size=parameters.replay_memory_size,\n",
    "                                              state_shape=parameters.state_length,\n",
    "                                              num_actions = self.num_actions,\n",
    "                                              discount_factor=self.discount_factor)\n",
    "            \n",
    "            self.train_model.build()\n",
    "            self.target_model.build()\n",
    "            \n",
    "            self.target_model.set_weights(self.train_model.get_weights())\n",
    "        \n",
    "    def act(self, state):\n",
    "        \n",
    "        if np.random.rand() < self.epsilon:\n",
    "            return np.random.randint(self.num_actions)\n",
    "        \n",
    "        values = self.target_model.model.predict(state)\n",
    "        \n",
    "        return np.argmax(values[0])\n",
    "    \n",
    "    def replay(self, batch_size):\n",
    "        \n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            target = reward\n",
    "            if not done:\n",
    "                target = reward + self.gamma * \\\n",
    "                       np.amax(self.model.predict(next_state)[0])\n",
    "            target_f = self.model.predict(state)\n",
    "            target_f[0][action] = target\n",
    "            self.model.fit(state, target_f, epochs=1, verbose=0)\n",
    "            \n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ReplayMemory:\n",
    "    \n",
    "    def __init__(self, memory_size, state_shape, num_actions, discount_factor):\n",
    "        \n",
    "        self.memory_size = memory_size\n",
    "        self.state_shape = state_shape\n",
    "        self.num_actions = num_actions\n",
    "        self.discount_factor = discount_factor\n",
    "        \n",
    "        self.states = np.zeros(shape=[memory_size] + state_shape, dtype=np.float64)\n",
    "        self.states_next = np.zeros(shape=[memory_size] + state_shape, dtype=np.float64)\n",
    "        self.actions = np.zeros(shape=[memory_size, num_actions], dtype=np.int8)\n",
    "        self.rewards = np.zeros(shape=[memory_size, num_actions], dtype=np.float64)\n",
    "        \n",
    "        self.indexes = cycle(range(memory_size))\n",
    "        self.pointer = next(self.indexes)\n",
    "        \n",
    "    def add(self, state, action, reward, next_state):\n",
    "        \n",
    "        k = self.pointer\n",
    "\n",
    "        self.states[k, :] = state\n",
    "        self.actions[k] = action\n",
    "        self.rewards[k] = reward  # TODO: consider clipping\n",
    "        self.states_next[k, :] = next_state\n",
    "        \n",
    "        self.pointer = next(self.indexes)\n",
    "        \n",
    "    def random_batch(self, batch_size):\n",
    "        \n",
    "        idx = np.random.randint(size, size=batch_size)\n",
    "        \n",
    "        return self.states[idx], self.actions[idx], self.rewards[idx], self.states_next[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    \n",
    "    def __init__(self,\n",
    "                 input_data,\n",
    "                 steps=None):\n",
    "        \n",
    "        self.steps = steps\n",
    "        self._load(input_data)\n",
    "        \n",
    "        self.episode = {}\n",
    "        \n",
    "    def _load(self, input_data):\n",
    "        \n",
    "        self.data = input_data\n",
    "        \n",
    "        self.shape = input_data.shape\n",
    "        \n",
    "        if self.steps is None or self.steps > self.shape[0]:\n",
    "            self.steps = self.shape[0] - 1\n",
    "    \n",
    "    def _seed(self):\n",
    "        \n",
    "        seed()\n",
    "    \n",
    "    def _add_state(self):\n",
    "        \n",
    "        np.insert(self.data, self.shape[1], np.zeros(self.shape[1]), axis=1)\n",
    "        \n",
    "    def reset(self):\n",
    "        \n",
    "        self._seed()\n",
    "        self.episode['start'] = np.random.randint(0, self.shape[0] - self.steps)\n",
    "        self.episode['current_index'] = self.episode.get('start')\n",
    "        #self.spisode['buy_price'] = 0\n",
    "        #self.data[:, -1] = 0  # Reset buy state\n",
    "        \n",
    "        return self.data[self.episode.get('current_index')]\n",
    "        \n",
    "    def step(self, action):\n",
    "        \n",
    "        current_index = self.episode.get('current_index')\n",
    "        state = self.data[current_index]\n",
    "        next_state = self.data[current_index + 1]\n",
    "        \n",
    "        price = state[0]  # TODO: add correct index for current price\n",
    "        \n",
    "        # TODO: add only buy once behavior maybe (penalty on every buy/sell should train not to buy many times)\n",
    "        \n",
    "        reward = 0       \n",
    "        \n",
    "        \n",
    "        self.episode['current_index'] += 1\n",
    "        \n",
    "        return next_state, reward\n",
    "    \n",
    "class Action(Enum):\n",
    "\n",
    "    HOLD = 0\n",
    "    BUY = 1\n",
    "    SELL = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = time_transform(data, 15)\n",
    "array = df.iloc[:,1:].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data processing parameters\n",
    "n = 15\n",
    "m = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Combine data\n",
    "df = time_transform(data, n)\n",
    "array = df.iloc[:,1:].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Normalize data \n",
    "# TODO: change normalization if necessary\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "normalized_array = min_max_scaler.fit_transform(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "states = np.stack([vectorize(normalized_array[x:x+m, :]) for x in range(normalized_array.shape[0] - m)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "EPISODES = 1\n",
    "EPISODE_LENGTH = 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1343 is out of bounds for axis 0 with size 1343",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-1b239a83abd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplay_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-76-0bd3f13b2f99>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mcurrent_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepisode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'current_index'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurrent_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mnext_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurrent_index\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mprice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# TODO: add correct index for current price\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1343 is out of bounds for axis 0 with size 1343"
     ]
    }
   ],
   "source": [
    "## Main loop\n",
    "\n",
    "parameters = Parameters()\n",
    "parameters.state_length = [states.shape[-1]]\n",
    "agent = Agent(parameters)\n",
    "env = Environment(states, steps=EPISODE_LENGTH)\n",
    "step = 0\n",
    "\n",
    "# Populate the replay memory with initial experiences\n",
    "state = env.reset()\n",
    "for i in range(parameters.replay_memory_size):\n",
    "    \n",
    "    action = agent.act(state)\n",
    "    next_state, reward = env.step(action)\n",
    "    agent.replay_memory.add(state, action, reward, next_state)\n",
    "    state = next_state\n",
    "\n",
    "for e in range(EPISODES):\n",
    "    \n",
    "    state = env.reset()\n",
    "    \n",
    "    for ii in range(EPISODE_LENGTH):\n",
    "        \n",
    "        # Update the target network weights every X iterations\n",
    "        if step % parameters.update_target_weights_step_size == 0:\n",
    "            print('Step {}: Updating target Q network weights with latest Q network weights.'.format(step))\n",
    "            self.target_model.interpolate_weights(self.train_model.get_weights(), target_estimator)\n",
    "                \n",
    "        action = agent.act(state)\n",
    "        next_state, reward = env.step(action)\n",
    "        agent.replay_memory.add(state, action, reward, next_state)\n",
    "        state = next_state\n",
    "        \n",
    "        if step % train_every_n_steps == 0:\n",
    "            print('Step {}: Sampling replay memory and training Q network.'.format(step))\n",
    "            samples = agent.replay_memory.random_batch(parameters.batch_size)\n",
    "            states_batch, action_batch, reward_batch, next_states_batch, done_batch = map(np.array, zip(*samples))\n",
    "\n",
    "            q_values_next = agent.train_model.predict(sess, next_states_batch)\n",
    "            best_actions = np.argmax(q_values_next, axis=1)\n",
    "            q_values_next_target = agent.target_model.predict(sess, next_states_batch)\n",
    "            targets_batch = reward_batch + discount_factor * q_values_next_target[np.arange(batch_size), best_actions]\n",
    "\n",
    "            states_batch = np.array(states_batch)\n",
    "            agent.train_model.fit(states_batch, action_batch, targets_batch)\n",
    "            \n",
    "        step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
